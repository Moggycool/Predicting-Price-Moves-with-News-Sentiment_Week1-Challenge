{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Full EDA Notebook: Time Series + Topic Modeling + Publisher Analysis\n",
    "# ------------------------------------------\n",
    "\n",
    "# Step 1: Setup paths\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "print(\"SRC path added:\", src_path)\n",
    "\n",
    "output_dir = project_root / \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"Outputs will be saved to:\", output_dir)\n",
    "\n",
    "data_path = project_root / \"data\" / \"preprocessed_data.csv\"\n",
    "print(\"Using preprocessed data at:\", data_path)\n",
    "\n",
    "# Step 2: Import libraries\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Topic Modeling visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn    # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# Step 3: Reload modules\n",
    "import time_analysis\n",
    "import topic_modeling\n",
    "import publication_analysis\n",
    "\n",
    "importlib.reload(time_analysis)\n",
    "importlib.reload(topic_modeling)\n",
    "importlib.reload(publication_analysis)\n",
    "\n",
    "from time_analysis import TimeSeriesAnalyzer\n",
    "from topic_modeling import TopicModeler\n",
    "from publication_analysis import PublisherAnalyzer\n",
    "\n",
    "# ------------------------------------------\n",
    "# Part 1: Time Series Analysis\n",
    "# ------------------------------------------\n",
    "print(\"\\n=== Time Series Analysis ===\")\n",
    "ts_analyzer = TimeSeriesAnalyzer(str(data_path))\n",
    "daily_counts, spikes, hourly_counts = ts_analyzer.run()\n",
    "\n",
    "# Save CSV outputs\n",
    "daily_counts.to_csv(output_dir / \"daily_article_counts.csv\")\n",
    "hourly_counts.to_csv(output_dir / \"hourly_article_counts.csv\")\n",
    "\n",
    "# Daily trend plot\n",
    "ts_analyzer.plot_daily_trend(spikes=spikes)\n",
    "plt.savefig(output_dir / \"daily_trend.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Hourly distribution plot\n",
    "ts_analyzer.plot_hourly_distribution()\n",
    "plt.savefig(output_dir / \"hourly_distribution.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Weekday-hour heatmap\n",
    "ts_analyzer.plot_weekday_hour_heatmap()\n",
    "plt.savefig(output_dir / \"weekday_hour_heatmap.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------\n",
    "# Part 2: Topic Modeling\n",
    "# ------------------------------------------\n",
    "print(\"\\n=== Topic Modeling ===\")\n",
    "topic_modeler_obj = TopicModeler(\n",
    "    data_path=str(data_path),\n",
    "    num_topics=3,\n",
    "    max_features=1000,\n",
    "    sample_size=1000  # optional for speed\n",
    ")\n",
    "topics = topic_modeler_obj.run()\n",
    "\n",
    "# Save topics as text\n",
    "with open(output_dir / \"topics.txt\", \"w\") as f:\n",
    "    f.write(topics)\n",
    "\n",
    "# Interactive pyLDAvis visualization\n",
    "lda_vis_data = pyLDAvis.sklearn.prepare(\n",
    "    topic_modeler_obj.lda_model,\n",
    "    topic_modeler_obj.doc_term_matrix,\n",
    "    topic_modeler_obj.vectorizer,\n",
    "    mds='tsne'\n",
    ")\n",
    "pyLDAvis.display(lda_vis_data)\n",
    "\n",
    "# Save pyLDAvis HTML\n",
    "pyLDAvis.save_html(lda_vis_data, output_dir / \"lda_vis.html\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Part 3: Publisher Analysis\n",
    "# ------------------------------------------\n",
    "print(\"\\n=== Publisher Analysis ===\")\n",
    "pub_analyzer = PublisherAnalyzer(str(data_path))\n",
    "publisher_counts, domain_counts, news_type_dist = pub_analyzer.run_full_analysis(top_n=10, type_column=\"stock\")\n",
    "\n",
    "# Save CSV outputs\n",
    "publisher_counts.to_csv(output_dir / \"publisher_counts.csv\", header=True)\n",
    "domain_counts.to_csv(output_dir / \"domain_counts.csv\", header=True)\n",
    "news_type_dist.to_csv(output_dir / \"news_type_distribution.csv\")\n",
    "\n",
    "# Save and show top publisher plots\n",
    "pub_analyzer.plot_top_publishers(top_n=10)\n",
    "plt.savefig(output_dir / \"top_publishers.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save and show top domains plots\n",
    "pub_analyzer.plot_top_domains(top_n=10)\n",
    "plt.savefig(output_dir / \"top_domains.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… All outputs (CSV, PNG, HTML) are saved in the `outputs/` folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Moenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
