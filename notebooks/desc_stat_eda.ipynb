{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b14b188",
   "metadata": {},
   "source": [
    "# Task-1: Exploratory Data Analysis (EDA)- Descriptive Statistics\n",
    "\n",
    "This notebook performs **exploratory data analysis (EDA)** on the preprocessed news dataset, including:\n",
    "\n",
    "1. **Data Preprocessing**  \n",
    "   - Handling missing values  \n",
    "   - Text-specific cleaning  \n",
    "   - Date parsing and formatting  \n",
    "\n",
    "2. **Descriptive Statistics**  \n",
    "   - Headline length statistics  \n",
    "   - Publisher activity  \n",
    "   - Trends over time  \n",
    "\n",
    "3. **Time Series Analysis**  \n",
    "   - Daily article frequency  \n",
    "   - Spike detection for market events  \n",
    "   - Hourly distribution of news  \n",
    "   - Weekday-hour heatmap  \n",
    "\n",
    "4. **Topic Modeling (NLP)**  \n",
    "   - Cleaning text and removing stopwords  \n",
    "   - Vectorization with CountVectorizer  \n",
    "   - Latent Dirichlet Allocation (LDA) for topic extraction  \n",
    "   - Displaying top words per topic  \n",
    "\n",
    "5. **Publisher Analysis**  \n",
    "   - Top contributing publishers  \n",
    "   - Domains if email addresses are used  \n",
    "   - Distribution of news type per publisher  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37dc30",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9172a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Step 1: Identify project root (parent of notebooks/)\n",
    "project_root = Path().resolve().parent\n",
    "\n",
    "# Step 2: Add src/ to import path\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "# Step 3: Import loader\n",
    "from data_loader import NewsDataLoader\n",
    "\n",
    "print(\"Import successful! Using src folder:\", src_path)\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DATA_DIR = Path(\n",
    "    r\"D:\\Python\\Week-1\"\n",
    "    r\"\\Predicting Price Moves with News Sentiment\"\n",
    "    r\"\\Predicting-Price-Moves-with-News-Sentiment_Week1-Challenge\"\n",
    "    r\"\\data\"\n",
    ")\n",
    "\n",
    "print(\"Base data directory set to:\", BASE_DATA_DIR)\n",
    "\n",
    "# Initialize\n",
    "loader = NewsDataLoader(BASE_DATA_DIR)  # pylint: disable=undefined-variable\n",
    "\n",
    "# Load dataset\n",
    "df = loader.load(\"raw_analyst_ratings.csv\")\n",
    "df.head()\n",
    "df.describe()\n",
    "df['publisher'].value_counts()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocess import NewsDataPreprocessor\n",
    "processor = NewsDataPreprocessor(BASE_DATA_DIR)\n",
    "df_clean = processor.preprocess(df)\n",
    "processor.save(df_clean)\n",
    "df_clean.head()\n",
    "df_clean.describe()\n",
    "df_clean['publisher'].value_counts()\n",
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# 1.1 Text Length: Create headline length column\n",
    "df[\"headline_length\"] = df[\"headline\"].astype(str).apply(len)\n",
    "\n",
    "# Summary statistics\n",
    "text_stats = df[\"headline_length\"].describe()\n",
    "print(\"Headline Length Statistics:\\n\", text_stats)\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "df[\"headline_length\"].plot(kind=\"hist\", bins=40)\n",
    "plt.title(\"Distribution of Headline Lengths\")\n",
    "plt.xlabel(\"Headline Length (characters)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a305f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Publisher article count\n",
    "publisher_counts = df[\"publisher\"].value_counts()\n",
    "\n",
    "print(\"\\nTop Publishers:\\n\")\n",
    "print(publisher_counts.head(20))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "publisher_counts.head(15).plot(kind=\"bar\")\n",
    "plt.title(\"Top 15 Most Active Publishers\")\n",
    "plt.xlabel(\"Publisher\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de68b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure date is datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Daily frequency\n",
    "daily_counts = df.groupby(df[\"date\"].dt.date).size()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_counts.plot()\n",
    "plt.title(\"Daily News Volume Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n",
    "\n",
    "# Weekly trend\n",
    "weekly_counts = df.groupby(df[\"date\"].dt.to_period(\"W\")).size()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "weekly_counts.plot()\n",
    "plt.title(\"Weekly News Volume Trend\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n",
    "\n",
    "# Monthly trend\n",
    "monthly_counts = df.groupby(df[\"date\"].dt.to_period(\"M\")).size()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_counts.plot()\n",
    "plt.title(\"Monthly News Volume Trend\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c3c656",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root (parent of notebooks folder)\n",
    "project_root = Path().resolve().parent\n",
    "\n",
    "# Add src folder to path\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "print(\"SRC path added:\", src_path)\n",
    "from topic_modeling import TopicModeler\n",
    "data_path = project_root / \"data\" / \"preprocessed_data.csv\"\n",
    "\n",
    "modeler = TopicModeler(\n",
    "    data_path=str(data_path),\n",
    "    num_topics=4,\n",
    "    max_features=1000,\n",
    "    sample_size=1000  # optional for speed\n",
    ")\n",
    "\n",
    "topics = modeler.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773c1b3",
   "metadata": {},
   "source": [
    "## Time Series-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Time Series Analysis Notebook\n",
    "# ------------------------------------------\n",
    "\n",
    "# Step 1: Add src folder to Python path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent   # parent of notebooks\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "print(\"SRC path added:\", src_path)\n",
    "\n",
    "# Step 2: Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Restart kernel first (in Jupyter: Kernel -> Restart Kernel)\n",
    "# Then, use importlib to reload the module\n",
    "import importlib\n",
    "import time_analysis  # your module\n",
    "\n",
    "importlib.reload(time_analysis)  # reloads the updated module\n",
    "\n",
    "from time_analysis import TimeSeriesAnalyzer\n",
    "\n",
    "# Optional: Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Step 3: Define path to preprocessed data\n",
    "data_path = project_root / \"data\" / \"preprocessed_data.csv\"\n",
    "print(\"Using preprocessed data at:\", data_path)\n",
    "# Initialize analyzer\n",
    "analyzer = TimeSeriesAnalyzer(str(data_path))\n",
    "\n",
    "# Run the standard analysis\n",
    "daily_counts, spikes, hourly_counts = analyzer.run()\n",
    "\n",
    "# Now the heatmap method exists\n",
    "analyzer.plot_weekday_hour_heatmap()\n",
    "\n",
    "# Step 5: Optional - Inspect results\n",
    "print(\"\\n--- Daily Counts (first 10 rows) ---\")\n",
    "print(daily_counts.head(10))\n",
    "\n",
    "print(\"\\n--- Detected Spikes ---\")\n",
    "print(spikes)\n",
    "\n",
    "print(\"\\n--- Hourly Distribution ---\")\n",
    "print(hourly_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2faf1",
   "metadata": {},
   "source": [
    "## Publisher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b326d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# Publisher Analysis Notebook\n",
    "# ------------------------------------------\n",
    "\n",
    "# Step 1: Add src folder to Python path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root (parent of notebooks folder)\n",
    "project_root = Path().resolve().parent\n",
    "\n",
    "# Add src folder to Python path\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "print(\"SRC path added:\", src_path)\n",
    "\n",
    "# Step 2: Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from publication_analysis import PublisherAnalyzer\n",
    "\n",
    "# Optional: Seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Step 3: Define path to preprocessed data\n",
    "data_path = project_root / \"data\" / \"preprocessed_data.csv\"\n",
    "print(\"Using preprocessed data at:\", data_path)\n",
    "\n",
    "# Step 4: Initialize PublisherAnalyzer\n",
    "analyzer = PublisherAnalyzer(str(data_path))\n",
    "\n",
    "# Step 5: Run full publisher analysis\n",
    "# This will:\n",
    "# 1) Count articles per publisher & plot top N\n",
    "# 2) Extract domains if emails are used & plot top N\n",
    "# 3) Show news type distribution per publisher (based on 'stock' column)\n",
    "publisher_counts, domain_counts, news_type_dist = analyzer.run_full_analysis(top_n=10, type_column=\"stock\")\n",
    "\n",
    "# Step 6: Inspect results if needed\n",
    "print(\"\\n--- Top 10 Publishers ---\")\n",
    "print(publisher_counts.head(10))\n",
    "\n",
    "print(\"\\n--- Top 10 Domains ---\")\n",
    "print(domain_counts.head(10))\n",
    "\n",
    "print(\"\\n--- News Type Distribution per Publisher (first 10 rows) ---\")\n",
    "print(news_type_dist.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Moenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
